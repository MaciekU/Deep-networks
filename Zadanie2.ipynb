{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import tensorflow as tf\n",
    "\n",
    "def shape_change( y):\n",
    "    y = (np.arange(10) == y).astype(np.float32)\n",
    "    return y\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "#x_train, x_test = x_train, x_test\n",
    "copy_x_test = x_test[0:11]\n",
    "copy_y_test = y_test[0:11]\n",
    "x_train, x_test = x_train/255.0, x_test/255.0\n",
    "y_train = shape_change( y_train)\n",
    "y_test = shape_change( y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularization_method = 2 #0 nic | 2 L2\n",
    "epochs = 100\n",
    "layers = 8 # 2 | 5 | 10\n",
    "optimalization_method = 0 #0 Adam | 1 Adagrad | 2 Adadelta \n",
    "train_size = 50000\n",
    "test_size = 10000\n",
    "\n",
    "x_train = x_train[:train_size]\n",
    "y_train = y_train[:train_size]\n",
    "x_test = x_test[:test_size]\n",
    "y_test = y_test[:test_size]\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "batch_size = 1000\n",
    "show_steps = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if layers == 8:\n",
    "\n",
    "    X = tf.placeholder(tf.float32, shape=(None, 32,32,3))#(batch_size, 3072))\n",
    "    Y = tf.placeholder(tf.float32, shape=(None, 10))#(batch_size, 10))\n",
    "    \n",
    "    conv1_filter = tf.Variable(tf.truncated_normal(shape=[3, 3, 3, 64], mean=0, stddev=0.08))#[x*y in out]\n",
    "    conv2_filter = tf.Variable(tf.truncated_normal(shape=[3, 3, 64, 64], mean=0, stddev=0.08))#[x*y in out]\n",
    "    # 222 wielkość filtra [filter_height, filter_width, in_channels, out_channels] \n",
    "\n",
    "    def Deep_Network(data):\n",
    "        \n",
    "        conv1 = tf.nn.conv2d(data, conv1_filter, strides=[1,1,1,1], padding='SAME')\n",
    "        conv1 = tf.nn.relu(conv1)\n",
    "        conv1_pool = tf.nn.max_pool(conv1, ksize=[1,3,3,1], strides=[1,2,2,1], padding='SAME')\n",
    "        # 111 mierzenie pooling 1)zmiana padding na valid | zmiana ksize na większy | zmiana strides\n",
    "        conv1_batch = tf.layers.batch_normalization(conv1_pool)\n",
    "        \n",
    "        conv2 = tf.nn.conv2d(conv1_batch, conv2_filter, strides=[1,1,1,1], padding='SAME')\n",
    "        conv2 = tf.nn.relu(conv2)\n",
    "        conv2_pool = tf.nn.max_pool(conv2, ksize=[1,3,3,1], strides=[1,2,2,1], padding='SAME')    \n",
    "        conv2_batch = tf.layers.batch_normalization(conv2_pool)\n",
    "        \n",
    "        flat = tf.contrib.layers.flatten(conv2_batch)\n",
    "        \n",
    "        full1 = tf.contrib.layers.fully_connected(inputs=flat, num_outputs=384, activation_fn=tf.nn.relu)\n",
    "        full1_batch = tf.layers.batch_normalization(full1)\n",
    "        full2 = tf.contrib.layers.fully_connected(inputs=full1_batch, num_outputs=192, activation_fn=tf.nn.relu)\n",
    "        out_layer = tf.contrib.layers.fully_connected(inputs=full2, num_outputs=10, activation_fn=tf.nn.softmax)\n",
    "\n",
    "\n",
    "       \n",
    "        return out_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-ad387a7faaf2>:11: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Epoch: 1 cost=2.41\n",
      "Accuracy1: 0.38372326\n",
      "Accuracy2: 0.37467495\n",
      "Accuracy valid: 0.3791990876197815\n",
      "Epoch: 2 cost=2.14\n",
      "Accuracy1: 0.47990403\n",
      "Accuracy2: 0.4708942\n",
      "Accuracy valid: 0.47539910674095154\n",
      "Epoch: 3 cost=2.06\n",
      "Accuracy1: 0.5280944\n",
      "Accuracy2: 0.5181036\n",
      "Accuracy valid: 0.5230990052223206\n",
      "Epoch: 4 cost=2.01\n",
      "Accuracy1: 0.5632873\n",
      "Accuracy2: 0.54530907\n",
      "Accuracy valid: 0.5542981624603271\n",
      "Epoch: 5 cost=1.99\n",
      "Accuracy1: 0.57788444\n",
      "Accuracy2: 0.56471294\n",
      "Accuracy valid: 0.5712987184524536\n",
      "Epoch: 6 cost=1.96\n",
      "Accuracy1: 0.60008\n",
      "Accuracy2: 0.58311665\n",
      "Accuracy valid: 0.5915983319282532\n",
      "Epoch: 7 cost=1.93\n",
      "Accuracy1: 0.61527693\n",
      "Accuracy2: 0.6037207\n",
      "Accuracy valid: 0.6094988584518433\n",
      "Epoch: 8 cost=1.91\n",
      "Accuracy1: 0.6310738\n",
      "Accuracy2: 0.6189238\n",
      "Accuracy valid: 0.6249988079071045\n",
      "Epoch: 9 cost=1.91\n",
      "Accuracy1: 0.6338732\n",
      "Accuracy2: 0.62992597\n",
      "Accuracy valid: 0.6318995952606201\n",
      "Epoch: 10 cost=1.89\n",
      "Accuracy1: 0.63967204\n",
      "Accuracy2: 0.62872577\n",
      "Accuracy valid: 0.6341989040374756\n",
      "Epoch: 11 cost=1.88\n",
      "Accuracy1: 0.6632674\n",
      "Accuracy2: 0.6457291\n",
      "Accuracy valid: 0.6544982194900513\n",
      "Epoch: 12 cost=1.86\n",
      "Accuracy1: 0.6516697\n",
      "Accuracy2: 0.6455291\n",
      "Accuracy valid: 0.64859938621521\n",
      "Epoch: 13 cost=1.86\n",
      "Accuracy1: 0.6724655\n",
      "Accuracy2: 0.65573114\n",
      "Accuracy valid: 0.66409832239151\n",
      "Epoch: 14 cost=1.85\n",
      "Accuracy1: 0.6724655\n",
      "Accuracy2: 0.66573316\n",
      "Accuracy valid: 0.6690993309020996\n",
      "Epoch: 15 cost=1.84\n",
      "Accuracy1: 0.67286545\n",
      "Accuracy2: 0.66773355\n",
      "Accuracy valid: 0.6702995300292969\n",
      "Epoch: 16 cost=1.84\n",
      "Accuracy1: 0.6838632\n",
      "Accuracy2: 0.6815363\n",
      "Accuracy valid: 0.6826997995376587\n",
      "Epoch: 17 cost=1.83\n",
      "Accuracy1: 0.69526094\n",
      "Accuracy2: 0.68673736\n",
      "Accuracy valid: 0.6909991502761841\n",
      "Epoch: 18 cost=1.82\n",
      "Accuracy1: 0.69506097\n",
      "Accuracy2: 0.68113625\n",
      "Accuracy valid: 0.6880986094474792\n",
      "Epoch: 19 cost=1.81\n",
      "Accuracy1: 0.69266146\n",
      "Accuracy2: 0.6793359\n",
      "Accuracy valid: 0.6859986782073975\n",
      "Epoch: 20 cost=1.81\n",
      "Accuracy1: 0.69126177\n",
      "Accuracy2: 0.679936\n",
      "Accuracy valid: 0.6855988502502441\n",
      "Epoch: 21 cost=1.81\n",
      "Accuracy1: 0.7038592\n",
      "Accuracy2: 0.6855371\n",
      "Accuracy valid: 0.6946981549263\n",
      "Epoch: 22 cost=1.80\n",
      "Accuracy1: 0.7040592\n",
      "Accuracy2: 0.6953391\n",
      "Accuracy valid: 0.6996991634368896\n",
      "Epoch: 23 cost=1.80\n",
      "Accuracy1: 0.70925814\n",
      "Accuracy2: 0.69973993\n",
      "Accuracy valid: 0.7044990062713623\n",
      "Epoch: 24 cost=1.79\n",
      "Accuracy1: 0.7164567\n",
      "Accuracy2: 0.7005401\n",
      "Accuracy valid: 0.7084984183311462\n",
      "Epoch: 25 cost=1.78\n",
      "Accuracy1: 0.7210558\n",
      "Accuracy2: 0.70414084\n",
      "Accuracy valid: 0.7125983238220215\n",
      "Epoch: 26 cost=1.79\n",
      "Accuracy1: 0.7016597\n",
      "Accuracy2: 0.7015403\n",
      "Accuracy valid: 0.7015999555587769\n",
      "Epoch: 27 cost=1.78\n",
      "Accuracy1: 0.6784643\n",
      "Accuracy2: 0.67053413\n",
      "Accuracy valid: 0.6744992136955261\n",
      "Epoch: 28 cost=1.78\n",
      "Accuracy1: 0.70785844\n",
      "Accuracy2: 0.6891378\n",
      "Accuracy valid: 0.6984981298446655\n",
      "Epoch: 29 cost=1.77\n",
      "Accuracy1: 0.7270546\n",
      "Accuracy2: 0.7135427\n",
      "Accuracy valid: 0.7202986478805542\n",
      "Epoch: 30 cost=1.77\n",
      "Accuracy1: 0.7366527\n",
      "Accuracy2: 0.7213443\n",
      "Accuracy valid: 0.7289984822273254\n",
      "Epoch: 31 cost=1.75\n",
      "Accuracy1: 0.72765446\n",
      "Accuracy2: 0.7213443\n",
      "Accuracy valid: 0.7244993448257446\n",
      "Epoch: 32 cost=1.75\n",
      "Accuracy1: 0.7418516\n",
      "Accuracy2: 0.73274654\n",
      "Accuracy valid: 0.7372990846633911\n",
      "Epoch: 33 cost=1.75\n",
      "Accuracy1: 0.7360528\n",
      "Accuracy2: 0.7275455\n",
      "Accuracy valid: 0.7317991256713867\n",
      "Epoch: 34 cost=1.74\n",
      "Accuracy1: 0.73365325\n",
      "Accuracy2: 0.71734345\n",
      "Accuracy valid: 0.7254983186721802\n",
      "Epoch: 35 cost=1.74\n",
      "Accuracy1: 0.7318536\n",
      "Accuracy2: 0.7169434\n",
      "Accuracy valid: 0.7243984937667847\n",
      "Epoch: 36 cost=1.74\n",
      "Accuracy1: 0.7224555\n",
      "Accuracy2: 0.7191438\n",
      "Accuracy valid: 0.7207996845245361\n",
      "Epoch: 37 cost=1.73\n",
      "Accuracy1: 0.73705256\n",
      "Accuracy2: 0.7289458\n",
      "Accuracy valid: 0.7329992055892944\n",
      "Epoch: 38 cost=1.73\n",
      "Accuracy1: 0.735253\n",
      "Accuracy2: 0.7235447\n",
      "Accuracy valid: 0.7293988466262817\n",
      "Epoch: 39 cost=1.72\n",
      "Accuracy1: 0.7316537\n",
      "Accuracy2: 0.72634524\n",
      "Accuracy valid: 0.7289994955062866\n",
      "Epoch: 40 cost=1.71\n",
      "Accuracy1: 0.73225355\n",
      "Accuracy2: 0.7303461\n",
      "Accuracy valid: 0.7312998175621033\n",
      "Epoch: 41 cost=1.72\n",
      "Accuracy1: 0.72985405\n",
      "Accuracy2: 0.7215443\n",
      "Accuracy valid: 0.7256991863250732\n",
      "Epoch: 42 cost=1.73\n",
      "Accuracy1: 0.71965605\n",
      "Accuracy2: 0.71674335\n",
      "Accuracy valid: 0.7181997299194336\n",
      "Epoch: 43 cost=1.73\n",
      "Accuracy1: 0.7316537\n",
      "Accuracy2: 0.7215443\n",
      "Accuracy valid: 0.7265989780426025\n",
      "Epoch: 44 cost=1.72\n",
      "Accuracy1: 0.7294541\n",
      "Accuracy2: 0.72514504\n",
      "Accuracy valid: 0.7272995710372925\n",
      "Epoch: 45 cost=1.71\n",
      "Accuracy1: 0.7240552\n",
      "Accuracy2: 0.7183437\n",
      "Accuracy valid: 0.7211993932723999\n",
      "Epoch: 46 cost=1.71\n",
      "Accuracy1: 0.7384523\n",
      "Accuracy2: 0.7373475\n",
      "Accuracy valid: 0.737899899482727\n",
      "Epoch: 47 cost=1.70\n",
      "Accuracy1: 0.735053\n",
      "Accuracy2: 0.7303461\n",
      "Accuracy valid: 0.7326995134353638\n",
      "Epoch: 48 cost=1.70\n",
      "Accuracy1: 0.73705256\n",
      "Accuracy2: 0.7259452\n",
      "Accuracy valid: 0.7314988374710083\n",
      "Epoch: 49 cost=1.70\n",
      "Accuracy1: 0.7408518\n",
      "Accuracy2: 0.7319464\n",
      "Accuracy valid: 0.7363991141319275\n",
      "Epoch: 50 cost=1.70\n",
      "Accuracy1: 0.7268546\n",
      "Accuracy2: 0.72634524\n",
      "Accuracy valid: 0.726599931716919\n",
      "Epoch: 51 cost=1.70\n",
      "Accuracy1: 0.7330534\n",
      "Accuracy2: 0.7253451\n",
      "Accuracy valid: 0.729199230670929\n",
      "Epoch: 52 cost=1.69\n",
      "Accuracy1: 0.7390522\n",
      "Accuracy2: 0.7379476\n",
      "Accuracy valid: 0.7384998798370361\n",
      "Epoch: 53 cost=1.69\n",
      "Accuracy1: 0.74045193\n",
      "Accuracy2: 0.7445489\n",
      "Accuracy valid: 0.7425004243850708\n",
      "Epoch: 54 cost=1.69\n",
      "Accuracy1: 0.7430514\n",
      "Accuracy2: 0.7415483\n",
      "Accuracy valid: 0.7422998547554016\n",
      "Epoch: 55 cost=1.69\n",
      "Accuracy1: 0.740052\n",
      "Accuracy2: 0.7395479\n",
      "Accuracy valid: 0.739799976348877\n",
      "Epoch: 56 cost=1.69\n",
      "Accuracy1: 0.7376525\n",
      "Accuracy2: 0.7409482\n",
      "Accuracy valid: 0.7393003702163696\n",
      "Epoch: 57 cost=1.69\n",
      "Accuracy1: 0.7340532\n",
      "Accuracy2: 0.73974794\n",
      "Accuracy valid: 0.7369005680084229\n",
      "Epoch: 58 cost=1.69\n",
      "Accuracy1: 0.73805237\n",
      "Accuracy2: 0.7373475\n",
      "Accuracy valid: 0.7376999258995056\n",
      "Epoch: 59 cost=1.69\n",
      "Accuracy1: 0.74725056\n",
      "Accuracy2: 0.74274856\n",
      "Accuracy valid: 0.7449995279312134\n",
      "Epoch: 60 cost=1.67\n",
      "Accuracy1: 0.73565286\n",
      "Accuracy2: 0.7361472\n",
      "Accuracy valid: 0.7359000444412231\n",
      "Epoch: 61 cost=1.67\n",
      "Accuracy1: 0.7394521\n",
      "Accuracy2: 0.7331466\n",
      "Accuracy valid: 0.7362993955612183\n",
      "Epoch: 62 cost=1.67\n",
      "Accuracy1: 0.74265146\n",
      "Accuracy2: 0.7393479\n",
      "Accuracy valid: 0.740999698638916\n",
      "Epoch: 63 cost=1.67\n",
      "Accuracy1: 0.73225355\n",
      "Accuracy2: 0.7355471\n",
      "Accuracy valid: 0.7339003086090088\n",
      "Epoch: 64 cost=1.68\n",
      "Accuracy1: 0.72885424\n",
      "Accuracy2: 0.73494697\n",
      "Accuracy valid: 0.7319005727767944\n",
      "Epoch: 65 cost=1.67\n",
      "Accuracy1: 0.73705256\n",
      "Accuracy2: 0.74334866\n",
      "Accuracy valid: 0.7402006387710571\n",
      "Epoch: 66 cost=1.67\n",
      "Accuracy1: 0.7388522\n",
      "Accuracy2: 0.74054813\n",
      "Accuracy valid: 0.739700198173523\n",
      "Epoch: 67 cost=1.67\n",
      "Accuracy1: 0.734853\n",
      "Accuracy2: 0.7425485\n",
      "Accuracy valid: 0.7387007474899292\n",
      "Epoch: 68 cost=1.67\n",
      "Accuracy1: 0.7388522\n",
      "Accuracy2: 0.73574716\n",
      "Accuracy valid: 0.7372996807098389\n",
      "Epoch: 69 cost=1.67\n",
      "Accuracy1: 0.73425317\n",
      "Accuracy2: 0.7387478\n",
      "Accuracy valid: 0.7365005016326904\n",
      "Epoch: 70 cost=1.67\n",
      "Accuracy1: 0.7340532\n",
      "Accuracy2: 0.7425485\n",
      "Accuracy valid: 0.7383008599281311\n",
      "Epoch: 71 cost=1.67\n",
      "Accuracy1: 0.72725457\n",
      "Accuracy2: 0.7359472\n",
      "Accuracy valid: 0.7316008806228638\n",
      "Epoch: 72 cost=1.66\n",
      "Accuracy1: 0.7294541\n",
      "Accuracy2: 0.73634726\n",
      "Accuracy valid: 0.7329006791114807\n",
      "Epoch: 73 cost=1.66\n",
      "Accuracy1: 0.73685265\n",
      "Accuracy2: 0.7445489\n",
      "Accuracy valid: 0.7407007813453674\n",
      "Epoch: 74 cost=1.66\n",
      "Accuracy1: 0.7316537\n",
      "Accuracy2: 0.7395479\n",
      "Accuracy valid: 0.7356008291244507\n",
      "Epoch: 75 cost=1.66\n",
      "Accuracy1: 0.7188562\n",
      "Accuracy2: 0.72234446\n",
      "Accuracy valid: 0.7206003665924072\n",
      "Epoch: 76 cost=1.66\n",
      "Accuracy1: 0.7430514\n",
      "Accuracy2: 0.74194837\n",
      "Accuracy valid: 0.7424998879432678\n",
      "Epoch: 77 cost=1.66\n",
      "Accuracy1: 0.7316537\n",
      "Accuracy2: 0.73334664\n",
      "Accuracy valid: 0.7325001955032349\n",
      "Epoch: 78 cost=1.66\n",
      "Accuracy1: 0.7408518\n",
      "Accuracy2: 0.7435487\n",
      "Accuracy valid: 0.7422002553939819\n",
      "Epoch: 79 cost=1.66\n",
      "Accuracy1: 0.7422516\n",
      "Accuracy2: 0.74214846\n",
      "Accuracy valid: 0.7422000169754028\n",
      "Epoch: 80 cost=1.66\n",
      "Accuracy1: 0.7414517\n",
      "Accuracy2: 0.7381476\n",
      "Accuracy valid: 0.7397996187210083\n",
      "Epoch: 81 cost=1.65\n",
      "Accuracy1: 0.7244551\n",
      "Accuracy2: 0.7225445\n",
      "Accuracy valid: 0.7234997749328613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82 cost=1.66\n",
      "Accuracy1: 0.72785443\n",
      "Accuracy2: 0.7325465\n",
      "Accuracy valid: 0.730200469493866\n",
      "Epoch: 83 cost=1.65\n",
      "Accuracy1: 0.7376525\n",
      "Accuracy2: 0.74034804\n",
      "Accuracy valid: 0.7390002608299255\n",
      "Epoch: 84 cost=1.66\n",
      "Accuracy1: 0.74825037\n",
      "Accuracy2: 0.7555511\n",
      "Accuracy valid: 0.7519007325172424\n",
      "Epoch: 85 cost=1.65\n",
      "Accuracy1: 0.74725056\n",
      "Accuracy2: 0.74814963\n",
      "Accuracy valid: 0.7477000951766968\n",
      "Epoch: 86 cost=1.64\n",
      "Accuracy1: 0.7458508\n",
      "Accuracy2: 0.74894977\n",
      "Accuracy valid: 0.7474002838134766\n",
      "Epoch: 87 cost=1.63\n",
      "Accuracy1: 0.7318536\n",
      "Accuracy2: 0.74194837\n",
      "Accuracy valid: 0.7369009852409363\n",
      "Epoch: 88 cost=1.63\n",
      "Accuracy1: 0.7282544\n",
      "Accuracy2: 0.7311462\n",
      "Accuracy valid: 0.7297003269195557\n",
      "Epoch: 89 cost=1.63\n",
      "Accuracy1: 0.7324535\n",
      "Accuracy2: 0.74274856\n",
      "Accuracy valid: 0.7376010417938232\n",
      "Epoch: 90 cost=1.64\n",
      "Accuracy1: 0.7376525\n",
      "Accuracy2: 0.74674934\n",
      "Accuracy valid: 0.7422009110450745\n",
      "Epoch: 91 cost=1.64\n",
      "Accuracy1: 0.7344531\n",
      "Accuracy2: 0.74054813\n",
      "Accuracy valid: 0.7375006079673767\n",
      "Epoch: 92 cost=1.64\n",
      "Accuracy1: 0.7360528\n",
      "Accuracy2: 0.740148\n",
      "Accuracy valid: 0.7381004095077515\n",
      "Epoch: 93 cost=1.64\n",
      "Accuracy1: 0.7414517\n",
      "Accuracy2: 0.74774957\n",
      "Accuracy valid: 0.7446006536483765\n",
      "Epoch: 94 cost=1.63\n",
      "Accuracy1: 0.74425113\n",
      "Accuracy2: 0.7469494\n",
      "Accuracy valid: 0.7456002235412598\n",
      "Epoch: 95 cost=1.63\n",
      "Accuracy1: 0.7376525\n",
      "Accuracy2: 0.7445489\n",
      "Accuracy valid: 0.7411006689071655\n",
      "Epoch: 96 cost=1.63\n",
      "Accuracy1: 0.73785245\n",
      "Accuracy2: 0.7515503\n",
      "Accuracy valid: 0.7447013854980469\n",
      "Epoch: 97 cost=1.63\n",
      "Accuracy1: 0.73725253\n",
      "Accuracy2: 0.74914986\n",
      "Accuracy valid: 0.7432011961936951\n",
      "Epoch: 98 cost=1.63\n",
      "Accuracy1: 0.7324535\n",
      "Accuracy2: 0.7361472\n",
      "Accuracy valid: 0.7343003749847412\n",
      "Epoch: 99 cost=1.64\n",
      "Accuracy1: 0.73565286\n",
      "Accuracy2: 0.73974794\n",
      "Accuracy valid: 0.7377004027366638\n",
      "Epoch: 100 cost=1.64\n",
      "Accuracy1: 0.72665465\n",
      "Accuracy2: 0.72714543\n",
      "Accuracy valid: 0.726900041103363\n",
      "Tensor(\"fully_connected_2/Softmax:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"Placeholder_1:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#########################################################################################\n",
    "logits = Deep_Network(X)\n",
    "\n",
    "\n",
    "if regularization_method == 0 :   \n",
    "    loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "    \n",
    "if regularization_method == 2 :\n",
    "    variabl = tf.trainable_variables() \n",
    "    lossL2 = tf.add_n([ tf.nn.l2_loss(v) for v in variabl if 'w' in v.name ]) * 0.001\n",
    "    loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y) + lossL2)\n",
    " \n",
    "\n",
    "if optimalization_method == 0 :\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate) \n",
    "if optimalization_method == 1 :\n",
    "    optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)\n",
    "if optimalization_method == 2 :\n",
    "    optimizer = tf.train.AdadeltaOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "pred = tf.nn.softmax(logits, name=\"predictions\")\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    \n",
    "a1 = tf.argmax(Y,1)\n",
    "a2 = tf.argmax(logits,1)\n",
    "confusion_matrix = tf.confusion_matrix(labels = a1, predictions = a2)\n",
    "\n",
    "\n",
    "#tf.summary.histogram(\"predictions\", pred) #new\n",
    "\n",
    "wykres_acc1 = []\n",
    "cost_list = []\n",
    "#counter = 0\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    #train_writer = tf.summary.FileWriter( './logs/1/train ', sess.graph)#new\n",
    "    for epoch in range(epochs):\n",
    "        avg_cost = 0.0\n",
    "        total_batch = int(train_size/batch_size)\n",
    "\n",
    "        for i in range(total_batch): #trenowanie batchy\n",
    "            batch_x, batch_y = x_train[batch_size * i : batch_size * (i + 1)], y_train[batch_size * i : batch_size * (i + 1)]\n",
    "            #counter +=1\n",
    "            #merge = tf.summary.merge_all()\n",
    "            #summary,_, c = sess.run( [merge, train_op, loss_op], feed_dict={X: batch_x, Y: batch_y})\n",
    "            _, c = sess.run([train_op, loss_op], feed_dict={X: batch_x, Y: batch_y})\n",
    "            avg_cost += c / total_batch #koszt\n",
    "            #train_writer.add_summary(summary, counter)\n",
    "\n",
    "        if epoch % show_steps == 0:\n",
    "            \n",
    "            print(\"Epoch:\", (epoch+1), \"cost={:.2f}\".format(avg_cost))\n",
    "            cost_list.append(avg_cost)\n",
    "            acc1 = accuracy.eval({X: x_test[:5001], Y: y_test[:5001]})\n",
    "            acc2 = accuracy.eval({X: x_test[5001:10000], Y: y_test[5001:10000]})\n",
    "\n",
    "            wykres_acc1.append(acc1)\n",
    "\n",
    "            print(\"Accuracy1:\", acc1)\n",
    "            print(\"Accuracy2:\", acc2)\n",
    "            print(\"Accuracy valid:\", ((acc2+acc1)/2) )\n",
    "            #tf.summary.histogram(\"accuracy\", acc1) #new\n",
    "\n",
    "    #acc1 = accuracy.eval({X: x_test, Y: y_test})\n",
    "    #wykres_acc1.append(acc1)\n",
    "    #print(\"End accuracy:\", acc1)\n",
    "    \n",
    "   \n",
    "    \n",
    "    #print(confusion_matrix.eval({X: x_test, Y: y_test}))\n",
    "\n",
    "    print(logits)\n",
    "    print(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''%matplotlib inline\n",
    "import pylab\n",
    "x = list(range(1, epoch+3))\n",
    "y = wykres_acc1\n",
    "pylab.ylabel('Accuracy')\n",
    "pylab.plot(x,y,'bo', label='')\n",
    "pylab.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''%matplotlib inline\n",
    "import pylab\n",
    "x = list(range(1, epoch+2 ) )\n",
    "y = cost_list\n",
    "pylab.xlabel('Epoch')\n",
    "pylab.ylabel('Cost')\n",
    "pylab.plot(x,y,'bo', label='')\n",
    "pylab.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
